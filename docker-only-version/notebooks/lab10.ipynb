{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b23daab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in /opt/conda/lib/python3.9/site-packages (4.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ee73e7",
   "metadata": {},
   "source": [
    "# 1. Getting posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "439212ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient \n",
    "\n",
    "client = MongoClient('mongodb://root:example@mongo:27017/')\n",
    "db = client[\"wykopDB\"]\n",
    "\n",
    "posts_collection = db['posts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b11bcae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>author</th>\n",
       "      <th>comments_num</th>\n",
       "      <th>date</th>\n",
       "      <th>reactions_num</th>\n",
       "      <th>text</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61bb726482e4d1e5b3f3246f</td>\n",
       "      <td>Panitsch</td>\n",
       "      <td>8</td>\n",
       "      <td>2021-12-16 16:06:57</td>\n",
       "      <td>0</td>\n",
       "      <td>Mirki, na trasie Wrocław - Kraków muszę mieć j...</td>\n",
       "      <td>[0.38952746987342834, -0.19946804642677307, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61bb726482e4d1e5b3f32471</td>\n",
       "      <td>strongBAD</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-16 13:51:05</td>\n",
       "      <td>0</td>\n",
       "      <td>Czy ktoś we #wroclaw może polecić firmę która ...</td>\n",
       "      <td>[0.3574969172477722, -0.1804310530424118, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61bb726482e4d1e5b3f32473</td>\n",
       "      <td>DonVittorio</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-12-16 14:11:46</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.ratujemyzwierzaki.pl/wpotrzebie  #...</td>\n",
       "      <td>[0.22248169779777527, -0.14401127398014069, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61bb726482e4d1e5b3f32474</td>\n",
       "      <td>Pawelvk</td>\n",
       "      <td>9</td>\n",
       "      <td>2021-12-16 15:13:11</td>\n",
       "      <td>186</td>\n",
       "      <td>To miasto nigdy nie przestanie mnie zaskakiwać...</td>\n",
       "      <td>[0.2706601023674011, -0.07385268807411194, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61bb726482e4d1e5b3f32475</td>\n",
       "      <td>Cesarz_Polski</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-12-16 16:47:35</td>\n",
       "      <td>6</td>\n",
       "      <td>Jak na studiach. Wykładowca przynudza, a prymu...</td>\n",
       "      <td>[0.33495721220970154, -0.12751071155071259, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id         author  comments_num                 date  \\\n",
       "0  61bb726482e4d1e5b3f3246f       Panitsch             8  2021-12-16 16:06:57   \n",
       "1  61bb726482e4d1e5b3f32471      strongBAD             1  2021-12-16 13:51:05   \n",
       "2  61bb726482e4d1e5b3f32473    DonVittorio             5  2021-12-16 14:11:46   \n",
       "3  61bb726482e4d1e5b3f32474        Pawelvk             9  2021-12-16 15:13:11   \n",
       "4  61bb726482e4d1e5b3f32475  Cesarz_Polski             0  2021-12-16 16:47:35   \n",
       "\n",
       "   reactions_num                                               text  \\\n",
       "0              0  Mirki, na trasie Wrocław - Kraków muszę mieć j...   \n",
       "1              0  Czy ktoś we #wroclaw może polecić firmę która ...   \n",
       "2              3  https://www.ratujemyzwierzaki.pl/wpotrzebie  #...   \n",
       "3            186  To miasto nigdy nie przestanie mnie zaskakiwać...   \n",
       "4              6  Jak na studiach. Wykładowca przynudza, a prymu...   \n",
       "\n",
       "                                              vector  \n",
       "0  [0.38952746987342834, -0.19946804642677307, 0....  \n",
       "1  [0.3574969172477722, -0.1804310530424118, 0.04...  \n",
       "2  [0.22248169779777527, -0.14401127398014069, 0....  \n",
       "3  [0.2706601023674011, -0.07385268807411194, 0.1...  \n",
       "4  [0.33495721220970154, -0.12751071155071259, 0....  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "posts = posts_collection.find()\n",
    "\n",
    "texts = dict()\n",
    "with open(\"mongoDB.csv\", \"w+\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(posts[0].keys())\n",
    "    \n",
    "    for document in posts:\n",
    "        if document[\"text\"] not in texts or texts[document['text']]['reactions_num'] < document['reactions_num'] :\n",
    "            writer.writerow(document.values())\n",
    "            texts[document[\"text\"]] = document\n",
    "        \n",
    "df = pd.read_csv(\"mongoDB.csv\", delimiter=\",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ef32494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyspark\n",
    "# sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50818346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/03 14:38:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('lab10').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5319d45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- comments_num: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- reactions_num: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- vector: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.option(\"header\",True)\\\n",
    "            .option(\"quote\", \"\\\"\")\\\n",
    "            .option(\"escape\", \"\\\"\")\\\n",
    "            .csv(\"mongoDB.csv\")\n",
    "df.printSchema()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf2041b",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6c3bad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- comments_num: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- vector: vector (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- authorIndex: double (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------------+-------------------+-----+--------------------+--------------------+----+-----------+\n",
      "|                 _id|  author|comments_num|               date|label|                text|              vector|hour|authorIndex|\n",
      "+--------------------+--------+------------+-------------------+-----+--------------------+--------------------+----+-----------+\n",
      "|61bb726482e4d1e5b...|Panitsch|           8|2021-12-16 16:06:57|  0.0|Mirki, na trasie ...|[0.38952746987342...|  16|       43.0|\n",
      "+--------------------+--------+------------+-------------------+-----+--------------------+--------------------+----+-----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.functions import split, col\n",
    "from pyspark.sql.types import DoubleType, ArrayType, IntegerType\n",
    "from pyspark.ml.linalg import VectorUDT, Vectors\n",
    "\n",
    "# 1. hour column\n",
    "hour = F.udf(lambda x: int(x[11:13]), IntegerType())\n",
    "df = df.withColumn(\"hour\", hour(\"date\"))\n",
    "\n",
    "# 2. author column\n",
    "indexer = StringIndexer(inputCol=\"author\", outputCol=\"authorIndex\")\n",
    "df = indexer.fit(df).transform(df)\n",
    "\n",
    "# 3. cast vectors to double\n",
    "def str_to_list(string):\n",
    "    v_list = string[1:-1].split(\",\")\n",
    "    return list(map(float, v_list))\n",
    "\n",
    "remove_parentheses = F.udf(str_to_list, ArrayType(DoubleType()))\n",
    "df = df.withColumn(\"vector\", remove_parentheses(\"vector\"))\n",
    "\n",
    "seqAsVector = F.udf(lambda vs: Vectors.dense(vs), VectorUDT())\n",
    "df = df.withColumn(\"vector\", seqAsVector(\"vector\"))\n",
    "\n",
    "# 4. cast others\n",
    "df = df.withColumn(\"comments_num\", df[\"comments_num\"].cast(IntegerType()))\n",
    "df = df.withColumn(\"reactions_num\", df[\"reactions_num\"].cast(DoubleType()))\n",
    "\n",
    "#5. add labels\n",
    "df = df.withColumnRenamed(\"reactions_num\", \"label\")\n",
    "df.printSchema()\n",
    "df.show(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3599d147",
   "metadata": {},
   "source": [
    "# 3. Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0ddefd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train, test = df.randomSplit([0.8, 0.2])\n",
    "print(f'Train: {train.count()}')\n",
    "print(f'Test: {test.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f2ff51",
   "metadata": {},
   "source": [
    "# 4. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63902f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/03 14:39:28 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/01/03 14:39:28 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/01/03 14:39:28 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/01/03 14:39:28 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"comments_num\", \"vector\", \"hour\", \"authorIndex\"],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.001)\n",
    "pipeline = Pipeline(stages=[assembler, lr])\n",
    "\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b943543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61bc30fc55878f551ee23b62, Hebanowy_Krol) --> prediction=0.000000\n",
      "(61bc30fc55878f551ee23b65, Iudex) --> prediction=35.000000\n",
      "(61cdd429713262a02a8ed61d, ThrashMetal) --> prediction=1.000000\n",
      "(61cdd9ac713262a02a8ede0b, TenXen47) --> prediction=0.000000\n",
      "(61cedbbc9fe10ee2630fa7ab, Fritzowski) --> prediction=3.000000\n",
      "(61cedbbc9fe10ee2630fa7ad, kolej_ktora_jezdzila_po_psie) --> prediction=0.000000\n",
      "(61cedea19fe10ee2630fabd9, Landmark) --> prediction=9.000000\n",
      "(61cee2f897f3167d1c9f3504, beconase) --> prediction=17.000000\n",
      "(61cee2f897f3167d1c9f3508, maxyking) --> prediction=0.000000\n",
      "(61cee4519b653ad9965b7b6e, beconase) --> prediction=17.000000\n",
      "(61cef512665b6897ad149c25, beconase) --> prediction=17.000000\n",
      "(61cefdbf665b6897ad14ac36, Solitary_Man) --> prediction=2.000000\n",
      "(61cf0979665b6897ad14c18c, kzrr) --> prediction=3.000000\n",
      "(61cf09b4665b6897ad14c209, kzrr) --> prediction=3.000000\n",
      "(61cf0c0f665b6897ad14c65d, xan-kreigor) --> prediction=0.000000\n",
      "(61d0781d5f92d63cde7a2802, Czesiowcy) --> prediction=1.000000\n",
      "(61d0a9275f92d63cde7a3812, Jarasznikos) --> prediction=1.000000\n",
      "(61d0a9275f92d63cde7a381d, Rad-X) --> prediction=13.000000\n",
      "(61d0ba435f92d63cde7a53a7, Jarasznikos) --> prediction=1.000000\n",
      "(61d0ba435f92d63cde7a53ad, PrzewodniG) --> prediction=3.000000\n",
      "(61d2b634aefe9af53d9796d9, Lala-Sassy) --> prediction=0.000000\n",
      "(61d2b634aefe9af53d9796de, dabi) --> prediction=4.000000\n",
      "(61d2c4f0aefe9af53d97ae55, dabi) --> prediction=4.000000\n",
      "(61d2c4f0aefe9af53d97ae5c, nabbek) --> prediction=0.000000\n",
      "(61d2c5c1aefe9af53d97afbd, Zgrywajac_twardziela) --> prediction=5.000000\n",
      "(61d2c747aefe9af53d97b25d, Anesa) --> prediction=175.000000\n",
      "(61d2d210aefe9af53d97c3ef, bachus) --> prediction=0.000000\n",
      "(61d2d9ecaefe9af53d97d0fc, Anesa) --> prediction=175.000000\n",
      "(61d2ea92aefe9af53d97ebdb, Malchos) --> prediction=1.000000\n"
     ]
    }
   ],
   "source": [
    "def print_preditions(model, test):\n",
    "    predictions = model.transform(test)\n",
    "    selected = predictions.select(\"_id\", \"author\", \"prediction\")\n",
    "    for row in selected.collect():\n",
    "        rid, author, prediction = row \n",
    "        print(\n",
    "            \"(%s, %s) --> prediction=%f\" % (\n",
    "                rid, author, prediction\n",
    "            )\n",
    "        )\n",
    "    \n",
    "print_preditions(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47918548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 102.66063947079098\n",
      "R-squared = 0.024763394236431147\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "\n",
    "def validate(model, test):\n",
    "    predictions = model.transform(test)\n",
    "    predictions = predictions.select(\"_id\", \"prediction\").rdd.map(tuple)\n",
    "    true = test.rdd.map(lambda t: (t._id, t.label))\n",
    "\n",
    "    scoreAndLabels = predictions.join(true).map(lambda tup: tup[1])\n",
    "    metrics = RegressionMetrics(scoreAndLabels)\n",
    "\n",
    "    print(\"RMSE = %s\" % metrics.rootMeanSquaredError)\n",
    "    print(\"R-squared = %s\" % metrics.r2)\n",
    "\n",
    "validate(model, test)\n",
    "\n",
    "# OLD\n",
    "# RMSE = 6.087595874350708\n",
    "# R-squared = -0.33208955223880565"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122b3a12",
   "metadata": {},
   "source": [
    "# 5. Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0991734a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "lr = LogisticRegression() \n",
    "pipeline = Pipeline(stages=[assembler, lr])\n",
    "\n",
    "# regParam - regularization parameter \n",
    "# fitIntercept - whether to fit an intercept term.\n",
    "# elasticNetParam - ElasticNet mixing parameter, in range [0, 1].\n",
    "\n",
    "paramGrid = ParamGridBuilder()\\\n",
    ".addGrid(lr.regParam, [0.1, 0.01, 0.001])\\\n",
    ".addGrid(lr.fitIntercept, [False, True])\\\n",
    ".addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
    ".addGrid(lr.maxIter, [5, 10, 15])\\\n",
    ".build()\n",
    "\n",
    "\n",
    "tvs = TrainValidationSplit(estimator=pipeline,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=RegressionEvaluator(),\n",
    "                           trainRatio=0.8)\n",
    "\n",
    "model = tvs.fit(train)\n",
    "best_model = model.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373207d9",
   "metadata": {},
   "source": [
    "##### Best model params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e728e614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regParam': 0.001, 'fitIntercept': True, 'elasticNetParam': 0.0, 'maxIter': 5}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "java_model = best_model.stages[-1]._java_obj\n",
    "{param.name: java_model.getOrDefault(java_model.getParam(param.name)) \n",
    "    for param in paramGrid[0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88b8577",
   "metadata": {},
   "source": [
    "##### Best model predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25ff1c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61bc30fc55878f551ee23b62, Hebanowy_Krol) --> prediction=0.000000\n",
      "(61bc30fc55878f551ee23b65, Iudex) --> prediction=35.000000\n",
      "(61cdd429713262a02a8ed61d, ThrashMetal) --> prediction=4.000000\n",
      "(61cdd9ac713262a02a8ede0b, TenXen47) --> prediction=0.000000\n",
      "(61cedbbc9fe10ee2630fa7ab, Fritzowski) --> prediction=3.000000\n",
      "(61cedbbc9fe10ee2630fa7ad, kolej_ktora_jezdzila_po_psie) --> prediction=0.000000\n",
      "(61cedea19fe10ee2630fabd9, Landmark) --> prediction=9.000000\n",
      "(61cee2f897f3167d1c9f3504, beconase) --> prediction=29.000000\n",
      "(61cee2f897f3167d1c9f3508, maxyking) --> prediction=0.000000\n",
      "(61cee4519b653ad9965b7b6e, beconase) --> prediction=29.000000\n",
      "(61cef512665b6897ad149c25, beconase) --> prediction=29.000000\n",
      "(61cefdbf665b6897ad14ac36, Solitary_Man) --> prediction=2.000000\n",
      "(61cf0979665b6897ad14c18c, kzrr) --> prediction=3.000000\n",
      "(61cf09b4665b6897ad14c209, kzrr) --> prediction=3.000000\n",
      "(61cf0c0f665b6897ad14c65d, xan-kreigor) --> prediction=0.000000\n",
      "(61d0781d5f92d63cde7a2802, Czesiowcy) --> prediction=1.000000\n",
      "(61d0a9275f92d63cde7a3812, Jarasznikos) --> prediction=1.000000\n",
      "(61d0a9275f92d63cde7a381d, Rad-X) --> prediction=13.000000\n",
      "(61d0ba435f92d63cde7a53a7, Jarasznikos) --> prediction=1.000000\n",
      "(61d0ba435f92d63cde7a53ad, PrzewodniG) --> prediction=3.000000\n",
      "(61d2b634aefe9af53d9796d9, Lala-Sassy) --> prediction=0.000000\n",
      "(61d2b634aefe9af53d9796de, dabi) --> prediction=4.000000\n",
      "(61d2c4f0aefe9af53d97ae55, dabi) --> prediction=4.000000\n",
      "(61d2c4f0aefe9af53d97ae5c, nabbek) --> prediction=0.000000\n",
      "(61d2c5c1aefe9af53d97afbd, Zgrywajac_twardziela) --> prediction=23.000000\n",
      "(61d2c747aefe9af53d97b25d, Anesa) --> prediction=175.000000\n",
      "(61d2d210aefe9af53d97c3ef, bachus) --> prediction=0.000000\n",
      "(61d2d9ecaefe9af53d97d0fc, Anesa) --> prediction=175.000000\n",
      "(61d2ea92aefe9af53d97ebdb, Malchos) --> prediction=0.000000\n"
     ]
    }
   ],
   "source": [
    "print_preditions(best_model, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db286bc",
   "metadata": {},
   "source": [
    "##### Best model metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8149ffce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 102.8703569782257\n",
      "R-squared = 0.020774853067644483\n"
     ]
    }
   ],
   "source": [
    "validate(best_model, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
